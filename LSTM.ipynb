{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-07T04:41:01.345269Z","iopub.execute_input":"2022-01-07T04:41:01.345837Z","iopub.status.idle":"2022-01-07T04:41:01.371707Z","shell.execute_reply.started":"2022-01-07T04:41:01.345713Z","shell.execute_reply":"2022-01-07T04:41:01.370995Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:41:01.372936Z","iopub.execute_input":"2022-01-07T04:41:01.373301Z","iopub.status.idle":"2022-01-07T04:41:02.398740Z","shell.execute_reply.started":"2022-01-07T04:41:01.373262Z","shell.execute_reply":"2022-01-07T04:41:02.397898Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from pandas_datareader.data import DataReader\nfrom datetime import datetime\n# Get the stock quote\ndf = DataReader('AAPL', data_source='yahoo', start='2012-01-01', end=datetime.now())\n# Show teh data\ndf","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:41:02.399947Z","iopub.execute_input":"2022-01-07T04:41:02.400286Z","iopub.status.idle":"2022-01-07T04:41:03.711116Z","shell.execute_reply.started":"2022-01-07T04:41:02.400244Z","shell.execute_reply":"2022-01-07T04:41:03.710568Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title('Close Price History')\nplt.grid()\nplt.plot(df['Close'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:41:03.712599Z","iopub.execute_input":"2022-01-07T04:41:03.712993Z","iopub.status.idle":"2022-01-07T04:41:03.972822Z","shell.execute_reply.started":"2022-01-07T04:41:03.712964Z","shell.execute_reply":"2022-01-07T04:41:03.971991Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create a new dataframe with only the 'Close column \ndata = df.filter(['Close'])\n# Convert the dataframe to a numpy array\ndataset = data.values\n# Get the number of rows to train the model on\ntraining_data_len = int(np.ceil( len(dataset) * .95 ))\n\ntraining_data_len","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:41:03.973968Z","iopub.execute_input":"2022-01-07T04:41:03.974220Z","iopub.status.idle":"2022-01-07T04:41:03.981488Z","shell.execute_reply.started":"2022-01-07T04:41:03.974161Z","shell.execute_reply":"2022-01-07T04:41:03.980732Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:41:03.982587Z","iopub.execute_input":"2022-01-07T04:41:03.982829Z","iopub.status.idle":"2022-01-07T04:41:03.996821Z","shell.execute_reply.started":"2022-01-07T04:41:03.982801Z","shell.execute_reply":"2022-01-07T04:41:03.996249Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Scale the data\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:41:03.997790Z","iopub.execute_input":"2022-01-07T04:41:03.998517Z","iopub.status.idle":"2022-01-07T04:41:04.132815Z","shell.execute_reply.started":"2022-01-07T04:41:03.998473Z","shell.execute_reply":"2022-01-07T04:41:04.132250Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Create the training data set \n\ntrain_data = scaled_data[0:int(training_data_len), :]\n# Split the data into x_train and y_train data sets\nx_train = []\ny_train = []\n\nfor i in range(60, len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i, 0])\n    if i<= 61:\n        print(x_train)\n        print(y_train)\n        print()\n        \n# Convert the x_train and y_train to numpy arrays \nx_train, y_train = np.array(x_train), np.array(y_train)\n\n# Reshape the data\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:41:04.134027Z","iopub.execute_input":"2022-01-07T04:41:04.134650Z","iopub.status.idle":"2022-01-07T04:41:04.148516Z","shell.execute_reply.started":"2022-01-07T04:41:04.134604Z","shell.execute_reply":"2022-01-07T04:41:04.147699Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM\n\n# Build the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit(x_train, y_train, batch_size=1, epochs=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:41:04.150882Z","iopub.execute_input":"2022-01-07T04:41:04.151468Z","iopub.status.idle":"2022-01-07T04:42:34.171821Z","shell.execute_reply.started":"2022-01-07T04:41:04.151420Z","shell.execute_reply":"2022-01-07T04:42:34.170953Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create the testing data set \ntest_data = scaled_data[training_data_len - 60: , :]\n# Create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])\n    \n# Convert the data to a numpy array\nx_test = np.array(x_test)\n\n# Reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n\n# Get the models predicted price values \npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\nrmse","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:42:34.172884Z","iopub.execute_input":"2022-01-07T04:42:34.173073Z","iopub.status.idle":"2022-01-07T04:42:35.147612Z","shell.execute_reply.started":"2022-01-07T04:42:34.173049Z","shell.execute_reply":"2022-01-07T04:42:35.147056Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n# Visualize the data\nplt.figure(figsize=(16,6))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.plot(train['Close'])\nplt.plot(valid[['Close', 'Predictions']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:42:35.148593Z","iopub.execute_input":"2022-01-07T04:42:35.148955Z","iopub.status.idle":"2022-01-07T04:42:35.411888Z","shell.execute_reply.started":"2022-01-07T04:42:35.148926Z","shell.execute_reply":"2022-01-07T04:42:35.411078Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"valid","metadata":{"execution":{"iopub.status.busy":"2022-01-07T04:42:35.413137Z","iopub.execute_input":"2022-01-07T04:42:35.413879Z","iopub.status.idle":"2022-01-07T04:42:35.426204Z","shell.execute_reply.started":"2022-01-07T04:42:35.413836Z","shell.execute_reply":"2022-01-07T04:42:35.425247Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}